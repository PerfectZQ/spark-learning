# spark程序运行空指针异常的原因：
1.嵌套使用了RDD操作，比如在一个RDD map中又对另一个RDD进行了map操作。主要原因在于spark不支持RDD的嵌套操作。
2.在RDD操作中引用了object非原始类型(非int long等简单类型)的成员变量。貌似是由于object的成员变量默认是无法序列化的。解决方法：可以先将成员变量赋值给一个临时变量，然后使用该临时变量即可
3.spark 2.0.0对kryo序列化的依赖有bug，到SPARK_HOME/conf/spark-defaults.conf
	将默认： spark.serializer     org.apache.spark.serializer.KryoSerializer
	改为：	 spark.serializer 		org.apache.spark.serializer.JavaSerializer
	
#	java.io.NotSerializableException: org.apache.spark.SparkContext
sparkContext对象是不能被序列化的，sparkContext不可以出现在map函数中